# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
# –≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ –∑–∞–ø—É—Å–∫–∞ Streamlit

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

def test_data_loading():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    print("üîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")

    try:
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        data = pd.read_csv('data/predictive_maintenance.csv')
        print(f"‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {data.shape}")
        return data
    except FileNotFoundError:
        print("‚ùå –õ–æ–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ UCI
            from ucimlrepo import fetch_ucirepo
            dataset = fetch_ucirepo(id=601)
            data = pd.concat([dataset.data.features, dataset.data.targets], axis=1)
            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ UCI –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {data.shape}")
            return data
        except ImportError:
            print("‚ùå ucimlrepo –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ucimlrepo")
            return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ UCI: {e}")
            return None

def test_preprocessing(data):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏...")

    if data is None:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return None, None

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö
    processed_data = data.copy()

    # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
    columns_to_drop = ['UDI', 'Product ID']
    if 'Machine failure' in processed_data.columns:
        failure_columns = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']
        columns_to_drop.extend([col for col in failure_columns if col in processed_data.columns])
        target_column = 'Machine failure'
    else:
        target_column = 'Target'

    columns_to_drop = [col for col in columns_to_drop if col in processed_data.columns]
    if columns_to_drop:
        processed_data = processed_data.drop(columns=columns_to_drop)
        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã: {columns_to_drop}")

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    if 'Type' in processed_data.columns:
        le = LabelEncoder()
        processed_data['Type'] = le.fit_transform(processed_data['Type'])
        print("üî§ –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è 'Type' –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∞")

    # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    if target_column in processed_data.columns and target_column != 'Target':
        processed_data = processed_data.rename(columns={target_column: 'Target'})

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    if 'Target' in processed_data.columns:
        X = processed_data.drop(columns=['Target'])
        y = processed_data['Target']

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

        print(f"‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {X_scaled_df.shape} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {y.value_counts().to_dict()}")

        return X_scaled_df, y
    else:
        print("‚ùå –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return None, None

def test_models(X, y):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    print("\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")

    if X is None or y is None:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        return None

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    print(f"üìà –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)}")
    print(f"üìâ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_test)}")

    # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    models = {
        'Logistic Regression': LogisticRegression(random_state=42),
        'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42)  # –ú–µ–Ω—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
    }

    results = {}

    for name, model in models.items():
        print(f"ü§ñ –û–±—É—á–µ–Ω–∏–µ {name}...")

        try:
            # –û–±—É—á–µ–Ω–∏–µ
            model.fit(X_train, y_train)

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]

            # –ú–µ—Ç—Ä–∏–∫–∏
            accuracy = accuracy_score(y_test, y_pred)
            roc_auc = roc_auc_score(y_test, y_pred_proba)
            conf_matrix = confusion_matrix(y_test, y_pred)

            results[name] = {
                'accuracy': accuracy,
                'roc_auc': roc_auc,
                'confusion_matrix': conf_matrix
            }

            print(f"  ‚úÖ Accuracy: {accuracy:.3f}")
            print(f"  ‚úÖ ROC-AUC: {roc_auc:.3f}")

        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")

    return results

def test_prediction(X, y):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")

    if X is None or y is None:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return

    # –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = LogisticRegression(random_state=42)
    model.fit(X_train, y_train)

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    new_data = pd.DataFrame({
        col: [X[col].mean()] for col in X.columns
    })

    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    prediction = model.predict(new_data)[0]
    prediction_proba = model.predict_proba(new_data)[0]

    print(f"üîÆ –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    print(f"  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {'–û–¢–ö–ê–ó' if prediction == 1 else '–ù–û–†–ú–ê'}")
    print(f"  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç–∫–∞–∑–∞: {prediction_proba[1]:.3f}")
    print(f"  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–æ—Ä–º—ã: {prediction_proba[0]:.3f}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    print("=" * 50)

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    data = test_data_loading()

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
    X, y = test_preprocessing(data)

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    results = test_models(X, y)

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    test_prediction(X, y)

    print("\n" + "=" * 50)
    print("‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

    if results:
        print("\nüìä –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        for model_name, metrics in results.items():
            print(f"  {model_name}:")
            print(f"    Accuracy: {metrics['accuracy']:.3f}")
            print(f"    ROC-AUC: {metrics['roc_auc']:.3f}")

if __name__ == "__main__":
    main()
